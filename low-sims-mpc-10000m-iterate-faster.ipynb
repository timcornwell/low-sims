{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model partition calibration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T11:47:57.385694Z",
     "start_time": "2019-01-18T11:47:56.270365Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "\n",
    "from data_models.parameters import arl_path\n",
    "\n",
    "import numpy\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pylab as pylab\n",
    "\n",
    "from data_models.memory_data_models import SkyModel\n",
    "from data_models.polarisation import PolarisationFrame\n",
    "\n",
    "from processing_library.util.coordinate_support import simulate_point, skycoord_to_lmn\n",
    "\n",
    "from wrappers.serial.calibration.calibration_control import calibrate_function, create_calibration_controls\n",
    "from wrappers.serial.skycomponent.operations import find_skycomponents, partition_skycomponent_neighbours\n",
    "\n",
    "from wrappers.serial.visibility.base import create_blockvisibility, copy_visibility\n",
    "from processing_library.image.operations import copy_image, create_empty_image_like\n",
    "from wrappers.serial.image.operations import show_image, qa_image\n",
    "from wrappers.serial.simulation.testing_support import create_named_configuration, \\\n",
    "    create_low_test_skycomponents_from_gleam, create_unittest_components\n",
    "from wrappers.serial.skycomponent.operations import filter_skycomponents_by_flux\n",
    "from wrappers.serial.simulation.mpc import create_gaintable_from_screen, sum_visibility_over_partitions, \\\n",
    "    calculate_sf_from_screen\n",
    "from wrappers.serial.skymodel.operations import show_skymodel\n",
    "\n",
    "from processing_components.simulation.mpc import expand_skymodel_by_skycomponents\n",
    "\n",
    "from wrappers.serial.imaging.primary_beams import create_low_test_beam\n",
    "from wrappers.serial.skycomponent.operations import apply_beam_to_skycomponent\n",
    "from wrappers.serial.imaging.base import create_image_from_visibility, advise_wide_field\n",
    "from wrappers.serial.image.operations import import_image_from_fits, export_image_to_fits\n",
    "\n",
    "from wrappers.arlexecute.visibility.coalesce import convert_blockvisibility_to_visibility\n",
    "from wrappers.arlexecute.skycomponent.operations import insert_skycomponent\n",
    "from wrappers.arlexecute.image.operations import smooth_image, show_components\n",
    "\n",
    "from workflows.arlexecute.pipelines.pipeline_arlexecute import continuum_imaging_list_arlexecute_workflow, \\\n",
    "    ical_list_arlexecute_workflow\n",
    "from workflows.serial.imaging.imaging_serial import invert_list_serial_workflow\n",
    "from workflows.serial.imaging.imaging_serial import weight_list_serial_workflow, taper_list_serial_workflow\n",
    "from workflows.serial.pipelines.pipeline_serial import continuum_imaging_list_serial_workflow, \\\n",
    "    ical_list_serial_workflow\n",
    "from data_models.data_model_helpers import import_skycomponent_from_hdf5, import_gaintable_from_hdf5\n",
    "\n",
    "from data_models.data_model_helpers import import_skymodel_from_hdf5\n",
    "from workflows.arlexecute.imaging.imaging_arlexecute import invert_list_arlexecute_workflow\n",
    "from workflows.arlexecute.skymodel.skymodel_arlexecute import predict_skymodel_list_arlexecute_workflow\n",
    "from workflows.arlexecute.skymodel.skymodel_arlexecute import extract_datamodels_skymodel_list_arlexecute_workflow\n",
    "from workflows.arlexecute.skymodel.skymodel_arlexecute import invert_skymodel_list_arlexecute_workflow\n",
    "from workflows.arlexecute.skymodel.skymodel_arlexecute import convolve_skymodel_list_arlexecute_workflow\n",
    "from wrappers.arlexecute.skymodel.operations import calculate_skymodel_equivalent_image, \\\n",
    "    update_skymodel_from_image, update_skymodel_from_gaintables\n",
    "from workflows.arlexecute.imaging.imaging_arlexecute import deconvolve_list_arlexecute_workflow\n",
    "from workflows.serial.imaging.imaging_serial import deconvolve_list_serial_workflow\n",
    "from data_models.data_model_helpers import export_skymodel_to_hdf5\n",
    "from workflows.arlexecute.calibration.calibration_arlexecute import calibrate_list_arlexecute_workflow\n",
    "\n",
    "from data_models.data_model_helpers import import_blockvisibility_from_hdf5\n",
    "\n",
    "from wrappers.arlexecute.execution_support.arlexecute import arlexecute\n",
    "from wrappers.arlexecute.execution_support.dask_init import get_dask_Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T11:47:57.390387Z",
     "start_time": "2019-01-18T11:47:57.387111Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "def init_logging():\n",
    "    logging.basicConfig(filename='results/low-sims-mpc.log',\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.DEBUG)\n",
    "\n",
    "init_logging()\n",
    "log = logging.getLogger()\n",
    "    \n",
    "def lprint(*args):\n",
    "    log.info(*args)\n",
    "    print(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T11:47:57.539317Z",
     "start_time": "2019-01-18T11:47:57.392647Z"
    }
   },
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14.0, 14.0)\n",
    "pylab.rcParams['image.cmap'] = 'rainbow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T11:47:59.573193Z",
     "start_time": "2019-01-18T11:47:57.541638Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LocalCluster and Dask Client\n",
      "Diagnostic pages available on port http://127.0.0.1:8787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:33377': None,\n",
       " 'tcp://127.0.0.1:34109': None,\n",
       " 'tcp://127.0.0.1:34889': None,\n",
       " 'tcp://127.0.0.1:35207': None,\n",
       " 'tcp://127.0.0.1:35963': None,\n",
       " 'tcp://127.0.0.1:38123': None,\n",
       " 'tcp://127.0.0.1:38167': None,\n",
       " 'tcp://127.0.0.1:38437': None,\n",
       " 'tcp://127.0.0.1:39577': None,\n",
       " 'tcp://127.0.0.1:40035': None,\n",
       " 'tcp://127.0.0.1:41225': None,\n",
       " 'tcp://127.0.0.1:43083': None,\n",
       " 'tcp://127.0.0.1:43443': None,\n",
       " 'tcp://127.0.0.1:44383': None,\n",
       " 'tcp://127.0.0.1:44791': None,\n",
       " 'tcp://127.0.0.1:45893': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_workers=16\n",
    "c = get_dask_Client(memory_limit=256 * 1024 * 1024 * 1024 // n_workers, n_workers=n_workers)\n",
    "arlexecute.set_client(client=c)\n",
    "arlexecute.run(init_logging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the previously prepared observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T11:48:03.735315Z",
     "start_time": "2019-01-18T11:47:59.575060Z"
    }
   },
   "outputs": [],
   "source": [
    "blockvis = import_blockvisibility_from_hdf5('results/low-sims-mpc-skymodel-noniso-blockvis_rmax10000.0.hdf5')\n",
    "Vobs = convert_blockvisibility_to_visibility(blockvis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T14:02:36.740636Z",
     "start_time": "2019-01-04T14:02:36.736655Z"
    }
   },
   "source": [
    "### Initialization phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:52:04.418597Z",
     "start_time": "2019-01-06T14:52:04.415028Z"
    }
   },
   "source": [
    "#### Read the previous iteration of skymodels, $\\theta_p^{(n)}$. Each skymodel will contain a mask based on the decomposition, an image and gaintable derived from ICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T12:19:02.688528Z",
     "start_time": "2019-01-18T11:48:03.737249Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timcornwell/anaconda3/envs/arl/lib/python3.6/site-packages/distributed/worker.py:901: UserWarning: Large object of size 134.22 MB detected in task graph: \n",
      "  ('getitem-a224e54c78644431467914e0f5f28c2b', <data ... -f460c0be37eb')\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  % (format_bytes(len(b)), s))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arlexecute.compute: Execution using Dask took 1821.802 seconds\n"
     ]
    }
   ],
   "source": [
    "nsources=14\n",
    "iteration=0\n",
    "rmax=10000.0\n",
    "theta_list = import_skymodel_from_hdf5(\"results/low-sims-mpc-skymodel_%dsources_iteration%d_rmax%.1f.hdf5\" % \n",
    "                                       (nsources, iteration, rmax))\n",
    "model = create_empty_image_like(theta_list[0].image)\n",
    "residual = create_empty_image_like(model)\n",
    "\n",
    "psf_obs = invert_list_arlexecute_workflow([Vobs], [model], context='2d', dopsf=True)\n",
    "future_Vobs = arlexecute.scatter(Vobs)\n",
    "theta_list = arlexecute.scatter(theta_list)\n",
    "\n",
    "for iteration in range(1,10):\n",
    "    Vdatamodel_list = predict_skymodel_list_arlexecute_workflow(future_Vobs, theta_list, context='2d', docal=True)\n",
    "    Vdatamodel_list = extract_datamodels_skymodel_list_arlexecute_workflow(future_Vobs, Vdatamodel_list)    \n",
    "    dirty_all_conv = convolve_skymodel_list_arlexecute_workflow(future_Vobs, theta_list, context='2d', docal=True)\n",
    "    dirty_all_cal = invert_skymodel_list_arlexecute_workflow(Vdatamodel_list, theta_list, context='2d', docal=True)\n",
    "    \n",
    "    def diff_dirty(dcal, dconv):\n",
    "        dcal[0].data -= dconv[0].data\n",
    "        return dcal    \n",
    "    dirty_all_cal = [arlexecute.execute(diff_dirty, nout=1)(dirty_all_cal[i], dirty_all_conv[i]) \n",
    "                     for i in range(len(dirty_all_cal))]\n",
    "    \n",
    "    def make_residual(dcal):\n",
    "        res = create_empty_image_like(model)\n",
    "        for i, d in enumerate(dcal):\n",
    "            res.data+=d[0].data\n",
    "        return res    \n",
    "    residual = arlexecute.execute(make_residual, nout=1)(dirty_all_cal)\n",
    "    \n",
    "    def find_peaks(d):\n",
    "        return numpy.max(numpy.abs(d[0].data))\n",
    "    peaks = [arlexecute.execute(find_peaks, nout=1)(d) for d in dirty_all_cal]\n",
    "    \n",
    "    def find_peak(ps):\n",
    "        peak = numpy.max(ps)\n",
    "        print(\"Peak is %.3f\" % peak)\n",
    "        return peak\n",
    "    peak = arlexecute.execute(find_peak, nout=1)(peaks)\n",
    "                \n",
    "    def deconvolve_update_sm_image(dirty, psf, sm, p):\n",
    "        d = deconvolve_list_serial_workflow([dirty], [psf], \n",
    "                                            [model], mask=sm.mask, algorithm='hogbom',\n",
    "                                            scales=[0,3,10], \n",
    "                                            fractional_threshold=0.3, threshold=0.3 * p,\n",
    "                                            gain=0.1, niter=1000,\n",
    "                                            psf_support=512)[0]\n",
    "        sm.image.data += sm.mask.data * d[0].data\n",
    "        return sm    \n",
    "    theta_list = [arlexecute.execute(deconvolve_update_sm_image, nout=1)(dirty_all_cal[ism], psf_obs[0], sm, peak)\n",
    "                  for ism, sm in enumerate(theta_list)]\n",
    "        \n",
    "    Vpredicted_list = predict_skymodel_list_arlexecute_workflow(future_Vobs, theta_list, context='2d', docal=True)\n",
    "    Vcalibrated, gaintable_list = calibrate_list_arlexecute_workflow(Vdatamodel_list, Vpredicted_list,\n",
    "                                            calibration_context='T',\n",
    "                                            iteration=0, global_solution=False)    \n",
    "    theta_list = arlexecute.execute(update_skymodel_from_gaintables, nout=len(theta_list))(theta_list, \n",
    "                                                                     gaintable_list, calibration_context='T') \n",
    "\n",
    "    def progress(res, tl_list, gt_list, it):\n",
    "        \n",
    "        print('Iteration %d' % it)\n",
    "        \n",
    "        print('Length of theta = %d' % len(tl_list))\n",
    "        \n",
    "        print(qa_image(res, context='Residual image: iteration %d' % it))\n",
    "        export_image_to_fits(res, \"results/low-sims-mpc-residual_%dsources_iteration%d_rmax%.1f.hdf5\" % \n",
    "                             (nsources, it, rmax))\n",
    "\n",
    "        combined_model = calculate_skymodel_equivalent_image(tl_list)\n",
    "        print(qa_image(combined_model, context='Combined model: iteration %d' % it))\n",
    "        export_image_to_fits(combined_model, \"results/low-sims-mpc-model_%dsources_iteration%d_rmax%.1f.hdf5\" % \n",
    "                             (nsources, it, rmax))\n",
    "    \n",
    "        plt.clf()\n",
    "        for i in range(len(tl_list)):\n",
    "            plt.plot(numpy.angle(tl_list[i].gaintable.gain[:,:,0,0,0]).flatten(),\n",
    "                     numpy.angle(gt_list[i]['T'].gain[:,:,0,0,0]).flatten(), \n",
    "                     '.')\n",
    "        plt.xlabel('Current phase')\n",
    "        plt.ylabel('Update to phase')\n",
    "        plt.xlim([-numpy.pi, numpy.pi])\n",
    "        plt.ylim([-numpy.pi, numpy.pi])\n",
    "        plt.title(\"MPC %dsources iteration%d: Change in phase\" % (nsources, it))\n",
    "        plt.savefig(\"figures/low-sims-mpc-skymodel-phase-change_%dsources_iteration%d.jpg\" % (nsources, it))\n",
    "        plt.show()\n",
    "        return tl_list\n",
    "    \n",
    "    theta_list = arlexecute.execute(progress, nout=len(theta_list))(residual, theta_list, gaintable_list, iteration)\n",
    "\n",
    "theta_list = arlexecute.compute(theta_list, sync=True)\n",
    "    \n",
    "export_skymodel_to_hdf5(theta_list, \"results/low-sims-mpc-skymodel_%dsources_iteration%d_rmax%.1f.hdf5\" % (nsources, iteration, rmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T12:19:05.096743Z",
     "start_time": "2019-01-18T12:19:02.693218Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_model = calculate_skymodel_equivalent_image(theta_list)\n",
    "export_image_to_fits(combined_model, 'results/low-sims-mpc-deconvolved_%dsources_rmax%.1f.fits' % (nsources, rmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T12:19:05.101169Z",
     "start_time": "2019-01-18T12:19:05.098192Z"
    }
   },
   "outputs": [],
   "source": [
    "from workflows.arlexecute.imaging.imaging_arlexecute import restore_list_arlexecute_workflow\n",
    "result=restore_list_arlexecute_workflow([combined_model], psf_obs, [(residual, 0.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T11:47:56.297Z"
    }
   },
   "outputs": [],
   "source": [
    "result=arlexecute.compute(result, sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T11:47:56.301Z"
    }
   },
   "outputs": [],
   "source": [
    "print(qa_image(result[0], context='MPC restored image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T11:47:56.322Z"
    }
   },
   "outputs": [],
   "source": [
    "recovered_mpccal_components = find_skycomponents(result[0], fwhm=2, threshold=0.14, npixels=12)\n",
    "print(len(recovered_mpccal_components))\n",
    "print(recovered_mpccal_components[0])\n",
    "from data_models.data_model_helpers import export_skycomponent_to_hdf5\n",
    "export_skycomponent_to_hdf5(recovered_mpccal_components, \n",
    "                            'results/low-sims-mpc-components_%dsources_rmax%.1f.hdf5' % (nsources, rmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T11:47:56.326Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_image(result[0], vmax=0.3, vmin=-0.03, components=recovered_mpccal_components)\n",
    "export_image_to_fits(result[0], 'results/low-sims-mpc-restored_%dsources_rmax%.1f.fits' % (nsources, rmax))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T11:47:56.330Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data_models.data_model_helpers import import_skymodel_from_hdf5\n",
    "gleam_skymodel_iso=import_skymodel_from_hdf5('results/low-sims-mpc-iso-skymodel_rmax%.1f.hdf5' % rmax)\n",
    "from processing_components.skycomponent.operations import filter_skycomponents_by_flux\n",
    "bright_gleam=filter_skycomponents_by_flux(gleam_skymodel_iso.components, flux_min=0.4)\n",
    "def max_flux(elem):\n",
    "    return numpy.max(elem.flux)\n",
    "sorted_bright_gleam=sorted(bright_gleam, key=max_flux, reverse=True)\n",
    "\n",
    "from wrappers.serial.skycomponent.operations import find_skycomponent_matches\n",
    "matches = find_skycomponent_matches(recovered_mpccal_components, sorted_bright_gleam, tol=1e-3)\n",
    "x=list()\n",
    "y=list()\n",
    "dx=list()\n",
    "dy=list()\n",
    "for match in matches:\n",
    "    y.append(recovered_mpccal_components[match[0]].flux[0,0])\n",
    "    x.append(sorted_bright_gleam[match[1]].flux[0,0])\n",
    "    dx.append(recovered_mpccal_components[match[0]].direction.ra.rad-sorted_bright_gleam[match[1]].direction.ra.rad)\n",
    "    dy.append(recovered_mpccal_components[match[0]].direction.dec.rad-sorted_bright_gleam[match[1]].direction.dec.rad)\n",
    "        \n",
    "plt.clf()\n",
    "plt.plot(x, y, '.')\n",
    "plt.xlim([0.0, 5.5])\n",
    "plt.ylim([0.0, 5.5])\n",
    "plt.xlabel('Input component flux')\n",
    "plt.ylabel('Recovered component flux')\n",
    "plt.title('Non-isoplanatic MPC %d sources case: flux recovered' % nsources)\n",
    "plt.savefig('low-sims-mpc_mpccal_noniso_%dsources_flux_errors.jpg' % nsources)\n",
    "plt.show()\n",
    "    \n",
    "plt.clf()\n",
    "plt.plot(dx, dy, '.')\n",
    "plt.xlim([-1e-3, 1e-3])\n",
    "plt.ylim([-1e-3, 1e-3])\n",
    "plt.xlabel('Error in RA (rad)')\n",
    "plt.ylabel('Error in Dec (rad)')\n",
    "plt.title('Non-isoplanatic MPC %d sources case: position error' % nsources)\n",
    "plt.savefig('low-sims-mpc_mpccal_noniso_%dsources_position_errors.jpg' % nsources)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T11:47:56.343Z"
    }
   },
   "outputs": [],
   "source": [
    "oldscreen=import_image_from_fits('screens/low_screen_5000.0r0_0.100rate.fits')\n",
    "from processing_components.simulation.ionospheric_screen import grid_gaintable_to_screen\n",
    "from processing_components.image.operations import create_empty_image_like\n",
    "newscreen = create_empty_image_like(oldscreen)\n",
    "gaintables = [th.gaintable for th in theta_list]\n",
    "newscreen, weights = grid_gaintable_to_screen(blockvis, gaintables, newscreen)\n",
    "print(qa_image(newscreen))\n",
    "export_image_to_fits(newscreen, 'results/low-sims-mpc_mpccal-screen_%dsources_rmax%.1f.fits' % (nsources, rmax))\n",
    "export_image_to_fits(weights, 'results/low-sims-mpc_mpccal-screenweights_%dsources_rmax%.1f.fits % (nsources, rmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T11:47:56.346Z"
    }
   },
   "outputs": [],
   "source": [
    "arlexecute.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T11:47:56.349Z"
    }
   },
   "outputs": [],
   "source": [
    "export_image_to_fits(result[0], 'results/low-sims-mpc-restored_%dsources_rmax%.1f.fits' % (nsources, rmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
